![image](https://github.com/Akashsinghpanwar/datascience-Nd-machine-laerning-project/assets/77565526/f11b9150-0a1e-4364-97e5-9f0b76c2c432)
To present your work, you will create a Jupyter Notebook (.ipynb file) where you show the following three experiments:
1.	The aim of the first experiment is to create a classifier capable of distinguishing between an abdominal ultrasound and a heart ultrasound. Therefore, you only need the images, and you can combine the “closed” and “open” folders to consider all heart images as such. Firstly, Import the images to the notebook (you can use the code seen in topic 3 and in the data loading tutorial) and run a stratified 80/20 train/test classification using two classifiers: a non-neural network one (i.e., SVM, RF, NB, or similar methods discussed in topics 3 and 6) and a neural network one (i.e., NN or CNN seen in topic 7 and 8 respectively). Report the results of both tested models using precision, recall and f1 score (taught in topic 5) and in a markdown cell, reflect on which one was the best model and why you think this is the case.
o	At this point, it is likely that your classifiers obtain “perfect” results given that the problem may be simple to address by the classifiers, especially if you parametrised them correctly. If that’s the case, run a five-fold cross-validation to verify that your original results are not simply the product of good luck in the splitting. If you didn’t obtain perfect results, then use a class imbalance handling technique (such as Keras imagedatagenerator or imgaug as seen in topic 5) to try to improve your results.
NOTE: If you are struggling to implement image augmentation, you could also extract some features from the images (e.g., Harris corners, HOG, SIFT, or SURF, as seen in topic 4) and apply a data augmentation technique such as SMOTE (seen in topic 5).
2.	Once you have decided which Machine Learning architecture yields the best results, use only the heart images to re-train that architecture, but now test if the new model can classify “open” or “closed” images correctly. This should be a straightforward 80/20 train/test validation. Report your results in terms of precision, recall, f1-score runtime, ROC and a confusion matrix and reflect on the results obtained so far in a markdown cell.
3.	Attempt to improve the results from the previous experiment by means of image/data augmentation or more advanced techniques, such as attention mechanisms (a.k.a. Transformers), Generative AI (GANs) or Transfer Learning (these concepts were seen in topic 9). Remember to keep the same test images that you obtained in experiment 2, and only manipulate the images on the training set so that the comparison is fair. Obtain the same metrics as in experiment 2 and report if there’s any change.

